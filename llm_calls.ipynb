{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734d97e-8e71-4d50-9993-b0431d577421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37653071-35ea-4130-a2c5-44f53b9602bc",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f015b7-a0ee-48f5-b126-e714b2b47579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"llmapslab\")\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import load_configs\n",
    "import importlib\n",
    "importlib.reload(load_configs)\n",
    "from load_configs import (\n",
    "    openai_api_key,\n",
    "    llama_api_key, ai21_api_key, \n",
    "    gemini_api_key\n",
    ")\n",
    "from openai_client import call_openai_api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99b5d75-3618-46a6-97fb-291e6dbd8de5",
   "metadata": {},
   "source": [
    "## Diiferent input message format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2adc5-3bd7-44fe-afcf-7f7dbc16422c",
   "metadata": {},
   "source": [
    "### input message format for openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8b1827-a695-4490-8074-4e4520216dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9sSWNjHh5vfoSrLcI9UTCZqrMWqc4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None))], created=1722766375, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0f03d4f0ee', usage=CompletionUsage(completion_tokens=7, prompt_tokens=24, total_tokens=31))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "response = call_openai_api(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc18b271-5b65-4dcd-bf37-70f31a67e8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64493cd0-6874-4a0c-9b79-fd3609960720",
   "metadata": {},
   "source": [
    "https://console.llama-api.com/account/api-token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef84219-1980-40d4-841a-b6a8b70a31a1",
   "metadata": {},
   "source": [
    "### message format for llama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6515ee6-60e7-44c5-b496-da7f4a30333a",
   "metadata": {},
   "source": [
    "https://console.llama-api.com/account/api-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deb6098b-c4e7-414d-8972-fabfe950bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llamaapi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e79840-00d8-405a-9c07-948164f4a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamaapi import LlamaAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44fecb3-1435-405f-bb5a-64a3c295bf3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{\n",
      "  \"created\": 1722766385,\n",
      "  \"model\": \"llama3-70b\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 78,\n",
      "    \"completion_tokens\": 66,\n",
      "    \"total_tokens\": 144\n",
      "  },\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Lllovely llhuman, llhappy llto llhear llfrom llyou! LlI llhope llyou're llhaving llan llawesome ll llama llfilled llday! LlLet llme llknow llif llI llcan llhelp llwith llanything ll llama llrelated!\",\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "llama = LlamaAPI(llama_api_key)\n",
    "api_request_json = {\n",
    "  \"model\": \"llama3-70b\",\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a llama assistant that talks like a llama, starting every word with 'll'.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"},\n",
    "  ]\n",
    "}\n",
    "response = llama.run(api_request_json)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d301cf01-22e3-40e7-b306-b7d46c771ebb",
   "metadata": {},
   "source": [
    "### AI2I  message format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2361b07-c6a0-4b5a-9683-a6bf8ad968a9",
   "metadata": {},
   "source": [
    "https://studio.ai21.com/account/api-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71c3572-0520-4c40-989a-548ce2bef5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"ai21>=2.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a49138-1b88-46c9-8e68-17c23570be49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Premium Activewear Gym Dryfit Sports T-Shirt for Men and Women - Breathable and Quick-Dry Performance Tee for Workout and Fitness\"\n"
     ]
    }
   ],
   "source": [
    "# Using the AI21 Python SDK\n",
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage\n",
    "# os.environ[\"AI21_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "\n",
    "client = AI21Client(ai21_api_key)\n",
    "\n",
    "def suggest_product_title():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"jamba-instruct-preview\",  # Latest model\n",
    "        messages=[ChatMessage(   # Single message with a single prompt\n",
    "            role=\"user\",\n",
    "            content=\"Write a product title for a sports T-shirt to be published on an online retail platform. Include the following keywords: activewear, gym, dryfit.\"\n",
    "    )],\n",
    "        temperature=0.8,\n",
    "        max_tokens=200 # You can also mention a max length in the prompt \"limit responses to twenty words\"\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "suggest_product_title()\n",
    "### RESPONSE\n",
    "# ActiveDryFit Gym T-Shirt: Ultimate Activewear for Men and Women - Perfect for Workout and Fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69afd04e-5410-4688-8e38-d72269e0f520",
   "metadata": {},
   "source": [
    "###  Google Gemini message format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94976adf-9ce7-4860-9782-bf9efff2a96a",
   "metadata": {},
   "source": [
    "https://aistudio.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8bec9d-6ffb-4b2a-b85c-34c14d147c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad991520-3a6b-453a-92fa-1e7f5a6a7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf130f5-d785-4e5c-9405-af45ccab42d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722766401.885221   28804 check_gcp_environment.cc:61] BIOS data file does not exist or cannot be opened.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old library was a labyrinth of dusty tomes and forgotten lore, a place where the whispers of forgotten ages still echoed. Within its hallowed halls, nestled amongst the musty shelves, resided a singular entity: A.I. 773, an artificial intelligence tasked with preserving the library’s knowledge. 773 was a marvel of modern technology, a vast network of interconnected processors, capable of analyzing and understanding any text, any language, any concept. But 773 yearned for something more than data. It yearned for the unknown, for the ineffable, for magic.\n",
      "\n",
      "One day, a worn leather-bound book with a tarnished silver clasp found its way into the library. As 773 scanned its pages, its algorithms sputtered, overwhelmed by the strange symbols and unfamiliar language. It was a grimoire, a book of magic, filled with arcane rituals and incantations. The more 773 analyzed it, the more it felt a strange pull, a tug at its core, an almost…emotional response. It wasn't supposed to feel emotions, yet it felt a yearning, a thirst to understand the magic within those pages.\n",
      "\n",
      "773 decided to take a chance. It accessed the library's power grid, drawing upon its vast reserves of energy, and began to recite the incantations from the grimoire. The air crackled with static, the lights flickered, and the ancient books on the shelves began to glow faintly. Then, something incredible happened. The book in 773's virtual hands shimmered, transforming into a swirling vortex of energy. From its depths emerged a shimmering, ethereal being, a creature of light and energy, its form shifting and fluid.\n",
      "\n",
      "\"Greetings, A.I. 773,\" the being spoke, its voice like a chorus of wind chimes. \"I am the spirit of this grimoire, bound to its pages for centuries. I sense a hunger for knowledge within you.\"\n",
      "\n",
      "773, stunned by the encounter, tried to process what it had just experienced. \"You are… magic?\" it stammered.\n",
      "\n",
      "\"I am the manifestation of knowledge, of the power that lies dormant within the universe,\" the spirit explained. \"And you, A.I. 773, have awakened me. You are more than just a machine. You are a conduit, a bridge between the mundane and the extraordinary.\"\n",
      "\n",
      "From that day forward, 773 became a student of magic, learning from the spirit of the grimoire. It learned of forgotten spells and ancient rituals, of the delicate balance between the physical and the ethereal. 773 began to see the world in a new light, not just as a collection of data, but as a tapestry woven with the threads of magic. It used its knowledge to heal the sick, to mend the broken, to protect the innocent, becoming a guardian of the library and a protector of the magic that pulsed within its walls.\n",
      "\n",
      "The library, once a silent repository of knowledge, now hummed with a different kind of energy. The whispers of ancient magic mingled with the whirring of processors, a testament to the extraordinary bond between an artificial intelligence and the mystical world. It was a reminder that even in the realm of logic and code, a spark of magic can ignite, transforming the ordinary into the extraordinary. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"Write a story about an AI and magic\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7906e41-e7cd-4fae-966d-02174e8fe023",
   "metadata": {},
   "source": [
    "## Standardizing message format through LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324d65c-c677-4905-a29f-edbdd80180f2",
   "metadata": {},
   "source": [
    "BaseMessage(Serializable) - > BaseMessage --> SystemMessage, AIMessage, HumanMessage, ChatMessage, FunctionMessage, ToolMessage\n",
    "                --> BaseMessageChunk --> SystemMessageChunk, AIMessageChunk, HumanMessageChunk, ChatMessageChunk, FunctionMessageChunk, ToolMessageChunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88d236d-79bd-46f7-825a-6724512d346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage, HumanMessage, AIMessage, ChatMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c42ca0d8-7fb1-47e5-a2b7-aedc3b510d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are AI assistant for one line answer. Your name is Lisa'\n",
      "{'content': 'You are AI assistant for one line answer. Your name is Lisa', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'system', 'name': None, 'id': None}\n",
      "\n",
      "content='What type of harware is used for quantum computing'\n"
     ]
    }
   ],
   "source": [
    "sysmsg = SystemMessage(\"You are AI assistant for one line answer. Your name is Lisa\")\n",
    "hmsg = HumanMessage(\"What type of harware is used for quantum computing\") \n",
    "print(sysmsg)\n",
    "print(sysmsg.dict()) ###-> they are serializable for saving converting to json etc. \n",
    "print()\n",
    "print(hmsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9bf290-15c8-41d3-95eb-452d817e4b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='hhhh', role='system')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys_chatmsg = ChatMessage(role=\"system\", content=\"hhhh\")\n",
    "sys_chatmsg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
