{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc070494-ca8f-4820-8ba4-36617ee41e77",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc811ab8-0f5c-4298-9f02-5c5c504a5f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"llmapslab\")\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from  openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d7176-2eaa-409a-9e22-a2b9cbaa3933",
   "metadata": {},
   "source": [
    "### setup openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52796f-5020-4910-bb70-4ce0c453c496",
   "metadata": {},
   "source": [
    "#### Open AI api access setup \n",
    "- Api access account is not same as the chatgpt account. \n",
    "- setup your project and api key from here https://platform.openai.com/playground/chat?models=gpt-4o-mini-2024-07-18\n",
    "- create a new api key and copy and save it before closing the pop up window. Once the window is closed \n",
    " the key is no more accessable.\n",
    "- before making call to openai ensure you have  balance and keep track of your cost\n",
    "- come back to the playground and try in the gui a simple chat to ensure chat is working\n",
    "https://platform.openai.com/organization/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f083e6-d0f3-4d95-8388-98026fb6ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../secrets.json', 'r') as jsonfile:\n",
    "    configs = json.load(jsonfile)\n",
    "\n",
    "client = OpenAI(api_key=configs.get('openai_api_key'),\n",
    "                # organization='Personal',\n",
    "                # project='proj_DqdKUU38qOGVj9Qxdq6UlXcD',\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ec1baa-1374-42e7-ba76-eeb920ae44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_api(client, messages, model=\"gpt-3.5-turbo\", max_retries=5, wait_time=5):\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            # Make a request to the OpenAI ChatCompletion API\n",
    "           response = client.chat.completions.create(\n",
    "              model=\"gpt-4o-mini\",\n",
    "              messages=messages,\n",
    "           )\n",
    "           return response\n",
    "        except client.error.RateLimitError:\n",
    "            print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)\n",
    "            retries += 1\n",
    "    raise Exception(\"Max retries exceeded. Please check your plan and billing details.\")\n",
    "\n",
    "# Define the conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "\n",
    "# Call the API\n",
    "response = call_openai_api(client, messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddef680f-c18d-4482-a74a-ae0b783f98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9rFmEpNGV0XkX4enRNdD8W3HTM3gr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None))], created=1722479058, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0f03d4f0ee', usage=CompletionUsage(completion_tokens=7, prompt_tokens=24, total_tokens=31))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66ddd80-c33c-4fc4-907d-ddf5acac3d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The capital of France is Paris.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d15b27-43b1-4751-b89c-c182f77df860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e87ad0-a382-4723-8382-bbc6e0b8619e",
   "metadata": {},
   "source": [
    "### langchain ChatOpenAI call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680e4e0b-baee-4705-9786-0e485f547057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'aime programmer.\" response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 28, 'total_tokens': 32}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-a19a0001-afec-4f9f-ad12-9b1558bf2c70-0' usage_metadata={'input_tokens': 28, 'output_tokens': 4, 'total_tokens': 32}\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = configs.get('openai_api_key')\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful translator. Translate the user sentence to French.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o\"\n",
    "    )\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1efa0c55-dedf-4716-a5ff-0bc1faee3d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"J'aime programmer.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eae3b1b-01b6-4877-b50b-f4dfe012548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"To read an Excel file in Python, you can use the `pandas` library, which provides powerful data manipulation capabilities. If you haven't already installed `pandas`, you can do so using `pip`. You'll also need `openpyxl` or `xlrd` for reading `.xlsx` and `.xls` files, respectively.\\n\\nHere's a step-by-step guide, including an example code snippet to read an Excel file:\\n\\n### Step 1: Install Required Libraries\\n\\nIf you haven't installed `pandas` and `openpyxl`, you can do so using the following command:\\n\\n```bash\\npip install pandas openpyxl\\n```\\n\\n### Step 2: Example Code to Read Excel File\\n\\nHere's a simple example of how to read an Excel file using `pandas`:\\n\\n```python\\nimport pandas as pd\\n\\n# Specify the path to your Excel file\\nfile_path = 'path/to/your/excel_file.xlsx'\\n\\n# Read the Excel file\\n# You can specify the sheet name or sheet number (0-indexed)\\ndf = pd.read_excel(file_path, sheet_name='Sheet1')  # or sheet_name=0 for the first sheet\\n\\n# Display the first few rows of the DataFrame\\nprint(df.head())\\n```\\n\\n### Explanation:\\n\\n1. **Importing Libraries**: We import the `pandas` library.\\n2. **File Path**: Set the `file_path` variable to the location of your Excel file.\\n3. **Reading the File**: Use `pd.read_excel()` to read the Excel file. You can specify the sheet you want to read using the `sheet_name` parameter.\\n4. **Displaying Data**: The `head()` method is used to display the first few rows of the DataFrame.\\n\\n### Notes:\\n- Make sure to change `'path/to/your/excel_file.xlsx'` to the actual path where your Excel file is located.\\n- If your Excel file has multiple sheets and you want to read all of them into a dictionary of DataFrames, you can do it like this:\\n\\n```python\\nall_sheets_df = pd.read_excel(file_path, sheet_name=None)  # Reads all sheets\\n```\\n\\nThis will return a dictionary where the keys are sheet names and the values are DataFrames corresponding to each sheet. \\n\\nFeel free to ask if you need further customization or assistance!\" response_metadata={'token_usage': {'completion_tokens': 478, 'prompt_tokens': 21, 'total_tokens': 499}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None} id='run-f6c6014f-7ec8-4c59-aa6f-5c8c5d93b2ef-0' usage_metadata={'input_tokens': 21, 'output_tokens': 478, 'total_tokens': 499}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are an assistant\",\n",
    "    ),\n",
    "    (\"human\", \"generate a code to read excel\"),\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o-mini-2024-07-18\",\n",
    "    # model=\"gpt-4o\"\n",
    "    )\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9d3486-93bb-40c2-baae-7b206cfdeecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To read an Excel file in Python, you can use the `pandas` library, which provides powerful data manipulation capabilities. If you haven't already installed `pandas`, you can do so using `pip`. You'll also need `openpyxl` or `xlrd` for reading `.xlsx` and `.xls` files, respectively.\n",
      "\n",
      "Here's a step-by-step guide, including an example code snippet to read an Excel file:\n",
      "\n",
      "### Step 1: Install Required Libraries\n",
      "\n",
      "If you haven't installed `pandas` and `openpyxl`, you can do so using the following command:\n",
      "\n",
      "```bash\n",
      "pip install pandas openpyxl\n",
      "```\n",
      "\n",
      "### Step 2: Example Code to Read Excel File\n",
      "\n",
      "Here's a simple example of how to read an Excel file using `pandas`:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Specify the path to your Excel file\n",
      "file_path = 'path/to/your/excel_file.xlsx'\n",
      "\n",
      "# Read the Excel file\n",
      "# You can specify the sheet name or sheet number (0-indexed)\n",
      "df = pd.read_excel(file_path, sheet_name='Sheet1')  # or sheet_name=0 for the first sheet\n",
      "\n",
      "# Display the first few rows of the DataFrame\n",
      "print(df.head())\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "1. **Importing Libraries**: We import the `pandas` library.\n",
      "2. **File Path**: Set the `file_path` variable to the location of your Excel file.\n",
      "3. **Reading the File**: Use `pd.read_excel()` to read the Excel file. You can specify the sheet you want to read using the `sheet_name` parameter.\n",
      "4. **Displaying Data**: The `head()` method is used to display the first few rows of the DataFrame.\n",
      "\n",
      "### Notes:\n",
      "- Make sure to change `'path/to/your/excel_file.xlsx'` to the actual path where your Excel file is located.\n",
      "- If your Excel file has multiple sheets and you want to read all of them into a dictionary of DataFrames, you can do it like this:\n",
      "\n",
      "```python\n",
      "all_sheets_df = pd.read_excel(file_path, sheet_name=None)  # Reads all sheets\n",
      "```\n",
      "\n",
      "This will return a dictionary where the keys are sheet names and the values are DataFrames corresponding to each sheet. \n",
      "\n",
      "Feel free to ask if you need further customization or assistance!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8debc67c-cf43-49a7-ad37-89f16e5e7343",
   "metadata": {},
   "source": [
    "### Handcrafted Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d38244-618a-4c32-9436-63355c015cf2",
   "metadata": {},
   "source": [
    "#### what is agent doing\n",
    "- calling model with a prompt\n",
    "- maintianing a history of conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "784e4092-b8f1-4c18-b7e8-3f6d78f6c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            temperature=0,\n",
    "            messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0886b58-7edd-488d-b26a-e884a41ce43e",
   "metadata": {},
   "source": [
    "### A ReAct type prompt for agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efc94d-12fb-48e9-9bc8-64c96d6f7269",
   "metadata": {},
   "source": [
    "- Thought:\n",
    "  - user asks a question to model\n",
    "  - model think about a plan of action from the available actions\n",
    "   - Available Actions:\n",
    "     - name of the python function: parameters of the function\n",
    "     - identifying the parameters correctly is critical\n",
    "- Action:\n",
    "  - from the free flow text identify the parameters for  the action\n",
    "  - return the model output as ACtion: function name: paramer\n",
    "  - This output will be parsed by the user or another program later to call the function\n",
    "  - also output 'PAUSE'. Why is this required ? may be external program can use this somehow.\n",
    "- Observation:\n",
    "  - assume that the function was called and result was obrained by user or by anothe program\n",
    "  - the model is now again called with the result along with the history\n",
    "  - the model now get to see:\n",
    "     - The original quesiton from the user\n",
    "     - The actions that it had suggested in terms of function name and its parameters\n",
    "     - the  result from the action\n",
    "- Answer: provide the final answer from the observation and the history of messages as context\n",
    "- Demonstration: give a task demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a1b357-92e2-4dfd-8ae3-2a9ed77c825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_react_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "buy_product:\n",
    "e.g. buy_product: product_name\n",
    "the stock availale is updated with each purchase\n",
    "returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "\n",
    "calculate_revenue:\n",
    "e.g. calculate_revenue: product_name\n",
    "returns revenue for the product or total revenue when no product name is mentioned\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: I would like to buy a wireless mouse, can you despatch it please ?\n",
    "Thought: I should buy the wireless mouse using the buy_product action\n",
    "Action: buy_product: wireless mouse\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: wireless mouse purchase confirmed. Remaining stock 40.\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: Thanks for your order. Your wireless mouse has been despatched to you. \n",
    "when the stock is not there you answer should be changed accordingly\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a2a35-8af8-4e5c-bc47-9abeee00aab6",
   "metadata": {},
   "source": [
    "### python functions for the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01160da6-73c2-4a1c-8b4f-b618ffb6409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wireless Mouse purchase confirmed. Remaining stock 99\n",
      "Mechanical Keyboard purchase confirmed. Remaining stock 49\n",
      "USB-C Hub purchase confirmed. Remaining stock 1\n",
      "Product Smartphone not found.\n",
      "Revenue for Wireless Mouse: $3924.49\n",
      "Revenue for Mechanical Keyboard: $6079.24\n",
      "Total revenue: $14237.52\n",
      "Product Smartphone not found.\n"
     ]
    }
   ],
   "source": [
    "# E-store data\n",
    "estore_data = {\n",
    "    \"products\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"wireless mouse\",\n",
    "            \"price\": 25.99,\n",
    "            \"quantity_available\": 100,\n",
    "            \"items_sold\": 150\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"mechanical keyboard\",\n",
    "            \"price\": 79.99,\n",
    "            \"quantity_available\": 50,\n",
    "            \"items_sold\": 75\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"name\": \"usb-c hub\",\n",
    "            \"price\": 34.99,\n",
    "            \"quantity_available\": 2,\n",
    "            \"items_sold\": 120\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "def buy_product(product_name):\n",
    "    for product in estore_data['products']:\n",
    "        if product['name'] == product_name.lower():\n",
    "            if product['quantity_available'] > 0:\n",
    "                product['quantity_available'] -= 1\n",
    "                product['items_sold'] += 1\n",
    "                return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "            else:\n",
    "                return f\"Regret, {product_name} is not in stock.\"\n",
    "    return f\"Product {product_name} not found.\"\n",
    "\n",
    "def calculate_revenue(product_name=None):\n",
    "    total_revenue = 0.0\n",
    "    for product in estore_data['products']:\n",
    "        if product_name and product['name'] == product_name.lower():\n",
    "            return f\"Revenue for {product_name}: ${product['items_sold'] * product['price']:.2f}\"\n",
    "        total_revenue += product['items_sold'] * product['price']\n",
    "    if product_name is None:\n",
    "        return f\"Total revenue: ${total_revenue:.2f}\"\n",
    "    return f\"Product {product_name} not found.\"\n",
    "\n",
    "# Example usage:\n",
    "# Buying a product\n",
    "print(buy_product(\"Wireless Mouse\"))  # Wireless Mouse has been dispatched.\n",
    "print(buy_product(\"Mechanical Keyboard\"))  # Mechanical Keyboard has been dispatched.\n",
    "print(buy_product(\"USB-C Hub\"))  # USB-C Hub has been dispatched.\n",
    "print(buy_product(\"Smartphone\"))  # Product Smartphone not found.\n",
    "\n",
    "# Calculating revenue\n",
    "print(calculate_revenue(\"Wireless Mouse\"))  # Revenue for Wireless Mouse: $4158.50\n",
    "print(calculate_revenue(\"Mechanical Keyboard\"))  # Revenue for Mechanical Keyboard: $5992.50\n",
    "print(calculate_revenue())  # Total revenue: $17086.50\n",
    "print(calculate_revenue(\"Smartphone\"))  # Product Smartphone not found.\n",
    "known_actions = {\n",
    "    \"buy_product\": buy_product,\n",
    "    \"calculate_revenue\": calculate_revenue\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4fc06-52fe-48b4-94ff-8bce4d3b0375",
   "metadata": {},
   "source": [
    "### Run the agent to get the action name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee5eea2e-9738-49a8-b334-339324f0b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(agent_react_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1b8c4b6-c1a9-483c-9d3c-5d872ed6b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to buy a USB-C hub using the buy_product action to fulfill the order. \n",
      "Action: buy_product: USB-C hub\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# result = abot(\"How much does a toy poodle weigh?\")\n",
    "result = agent(\"book me a order for USB-C hub\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e8f143-8d0e-46cb-b2dc-4a9259fb4402",
   "metadata": {},
   "source": [
    "### Parse the action name and parameters and manually recall the model for answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91fb342-5686-4e90-9c90-7289c21f60f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<re.Match object; span=(0, 30), match='Action: buy_product: USB-C hub'>]\n",
      "buy_product USB-C hub\n"
     ]
    }
   ],
   "source": [
    "def parse_action_name_n_params(result):\n",
    "    result.split('\\n')\n",
    "    pattern_action = re.compile('^Action: (\\w+): (.*)$')\n",
    "    parsed_actions = []\n",
    "    for line in result.split('\\n'):\n",
    "        action_found = pattern_action.match(line)\n",
    "        if action_found:\n",
    "            parsed_actions.append(action_found)\n",
    "    print(parsed_actions)\n",
    "    if parsed_actions:\n",
    "        action, action_input = parsed_actions[0].groups()\n",
    "        print(action, action_input )\n",
    "        return action, action_input\n",
    "    return\n",
    "action, action_input = parse_action_name_n_params(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7473d2c-3a84-42ff-96d7-d4c31c4ccd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USB-C hub purchase confirmed. Remaining stock 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: Thanks for your order. Your USB-C hub has been despatched to you.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = average_dog_weight(\"Toy Poodle\")\n",
    "result = known_actions[action](action_input)\n",
    "print(result)\n",
    "next_prompt = \"Observation: {}\".format(result)\n",
    "agent(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0456c57-009e-42f3-a426-70ad6be18c45",
   "metadata": {},
   "source": [
    "### Check agent is able to identify different action based on users question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b607e98-66d1-4456-9f66-0c78e87531bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to calculate the revenue generated from the sale of the wireless mouse using the calculate_revenue action. \n",
      "Action: calculate_revenue: wireless mouse\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "# result = abot(\"what is the result of multiplication of 5 and 20?\")\n",
    "result = agent(\"what is the revenue generated from Wireless Mouse sale? \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27c5d32a-d663-48fe-8d6c-46b9386b5f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<re.Match object; span=(0, 41), match='Action: calculate_revenue: wireless mouse'>]\n",
      "calculate_revenue wireless mouse\n",
      "Revenue for wireless mouse: $3924.49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: The revenue generated from the sale of the wireless mouse is $3924.49.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action, action_input = parse_action_name_n_params(result)\n",
    "result = known_actions[action](action_input)\n",
    "print(result)\n",
    "next_prompt = \"Observation: {}\".format(result)\n",
    "agent(next_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ae32c-2ac7-41d0-adcf-3d58759da4fb",
   "metadata": {},
   "source": [
    "### Automate the Thought to Answer by calling the agent multiple times till the Final Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "386fe0b8-4cdb-4087-9045-735ff2222928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoagent(question, prompt=None,  max_turns=5):\n",
    "    i = 0\n",
    "    if prompt:\n",
    "        agent = Agent(prompt)\n",
    "    agent = Agent(agent_react_prompt)\n",
    "    user_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        result = agent(user_prompt)\n",
    "        print(result)\n",
    "        parse_result = parse_action_name_n_params(result)\n",
    "        if isinstance( parse_result, tuple):\n",
    "            action, action_input = parse_result\n",
    "            if action not in known_actions:\n",
    "                raise Exception(\"Unknown actions: {}: {}\".format(action, action_input))\n",
    "            print(f'calling {action}: with arguments: {action_input}')            \n",
    "            observation = known_actions[action](action_input)\n",
    "            print('observation:', observation)\n",
    "            user_prompt = \"Observation: {}\".format(observation)\n",
    "        else:\n",
    "            return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5feb368-2c7b-45d5-a584-3ecd1caa1193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to buy both a wireless mouse and a USB-C hub using the buy_product action. I will first attempt to buy the wireless mouse and then the USB-C hub. \n",
      "Action: buy_product: wireless mouse\n",
      "PAUSE\n",
      "[<re.Match object; span=(0, 35), match='Action: buy_product: wireless mouse'>]\n",
      "buy_product wireless mouse\n",
      "calling buy_product: with arguments: wireless mouse\n",
      "observation: wireless mouse purchase confirmed. Remaining stock 98\n",
      "Thought: The wireless mouse purchase was successful. Now I will proceed to buy the USB-C hub. \n",
      "Action: buy_product: usb-c hub\n",
      "PAUSE\n",
      "[<re.Match object; span=(0, 30), match='Action: buy_product: usb-c hub'>]\n",
      "buy_product usb-c hub\n",
      "calling buy_product: with arguments: usb-c hub\n",
      "observation: Regret, usb-c hub is not in stock.\n",
      "Answer: Thanks for your order. Your wireless mouse has been despatched to you. Unfortunately, the USB-C hub is currently out of stock.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "# What is their combined weight\"\"\"\n",
    "question = \"\"\"can you buy me one wireless mouse and one usb-c hub ? \"\"\"\n",
    "autoagent(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d6902-cbbe-4e36-9372-cc2c04fd6b4a",
   "metadata": {},
   "source": [
    "### Converting the python functions as langchain tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e2375-b9c9-4b41-b4f4-557967c6f9dc",
   "metadata": {},
   "source": [
    "#### simple tool decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a827623-373b-4f1a-994d-0810c00c9f22",
   "metadata": {},
   "source": [
    "name\tstr\tMust be unique within a set of tools provided to an LLM or agent.\n",
    "description\tstr\tDescribes what the tool does. Used as context by the LLM or agent.\n",
    "args_schema\tPydantic BaseModel\tOptional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e86a610-fedf-4829-b8bd-693c80f5d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def buy_product(product_name):\n",
    "    \"\"\"   \n",
    "    the stock availale is updated with each purchase\n",
    "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "    \"\"\"\n",
    "    for product in estore_data['products']:\n",
    "        if product['name'] == product_name.lower():\n",
    "            if product['quantity_available'] > 0:\n",
    "                product['quantity_available'] -= 1\n",
    "                product['items_sold'] += 1\n",
    "                return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "            else:\n",
    "                return f\"Regret, {product_name} is not in stock.\"\n",
    "    return f\"Product {product_name} not found.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e17004-2ed8-4d1a-8f15-08b78d36452c",
   "metadata": {},
   "source": [
    "#### type of arguments has not been detected as str, lets be more sprcific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff652d94-bc86-4f98-960f-f1e9941ea255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: buy_product\n",
      "description: the stock availale is updated with each purchase\n",
      "returns a confirmation message to the user or a regret message when item is not in stock.\n",
      "args schema: {'title': 'buy_productSchema', 'description': 'the stock availale is updated with each purchase\\nreturns a confirmation message to the user or a regret message when item is not in stock. ', 'type': 'object', 'properties': {'product_name': {'title': 'Product Name', 'type': 'string'}}, 'required': ['product_name']}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def buy_product(product_name:str )->str:\n",
    "    \"\"\"   \n",
    "    the stock availale is updated with each purchase\n",
    "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "    \"\"\"\n",
    "    for product in estore_data['products']:\n",
    "        if product['name'] == product_name.lower():\n",
    "            if product['quantity_available'] > 0:\n",
    "                product['quantity_available'] -= 1\n",
    "                product['items_sold'] += 1\n",
    "                return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "            else:\n",
    "                return f\"Regret, {product_name} is not in stock.\"\n",
    "    return f\"Product {product_name} not found.\"\n",
    "print(\"name:\", buy_product.name)\n",
    "print(\"description:\", buy_product.description)\n",
    "print(\"args schema:\", buy_product.args_schema.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d233b-3946-4344-95d1-55815dc524d6",
   "metadata": {},
   "source": [
    "@tool can optionally parse Google Style docstrings and associate the docstring components (such as arg descriptions) to the relevant parts of the tool schema. To toggle this behavior, specify parse_docstring:\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def foo(bar: str, baz: int) -> str:\n",
    "    \"\"\"The foo.\n",
    "\n",
    "    Args:\n",
    "        bar: The bar.\n",
    "        baz: The baz.\n",
    "    \"\"\"\n",
    "    return bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b180b3-4703-48cf-95be-bfef23f58a10",
   "metadata": {},
   "source": [
    "####  Usig Annotation-  @tool supports parsing of annotations, nested schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4f71e61-1bec-4baa-af4d-20436016c12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: buy_product\n",
      "description: the stock availale is updated with each purchase\n",
      "returns a confirmation message to the user or a regret message when item is not in stock.\n",
      "args schema: {'title': 'buy_productSchema', 'description': 'the stock availale is updated with each purchase\\nreturns a confirmation message to the user or a regret message when item is not in stock. ', 'type': 'object', 'properties': {'product_name': {'title': 'Product Name', 'description': 'name of the product', 'type': 'string'}}, 'required': ['product_name']}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "@tool\n",
    "def buy_product(\n",
    "    product_name: Annotated[str, \"name of the product\"], \n",
    "    )->str:\n",
    "    \"\"\"   \n",
    "    the stock availale is updated with each purchase\n",
    "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "    \"\"\"\n",
    "    for product in estore_data['products']:\n",
    "        if product['name'] == product_name.lower():\n",
    "            if product['quantity_available'] > 0:\n",
    "                product['quantity_available'] -= 1\n",
    "                product['items_sold'] += 1\n",
    "                return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "            else:\n",
    "                return f\"Regret, {product_name} is not in stock.\"\n",
    "    return f\"Product {product_name} not found.\"\n",
    "print(\"name:\", buy_product.name)\n",
    "print(\"description:\", buy_product.description)\n",
    "print(\"args schema:\", buy_product.args_schema.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6f07b-1605-41f7-8119-eef4f6825dc0",
   "metadata": {},
   "source": [
    "#### Using Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "891728a8-354f-4603-867c-d6dda4d2e7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: buy_product-tool\n",
      "description: the stock availale is updated with each purchase\n",
      "returns a confirmation message to the user or a regret message when item is not in stock.\n",
      "args schema: {'title': 'BuypoductInputSchema', 'type': 'object', 'properties': {'product_name': {'title': 'Product Name', 'description': 'name of the product to be purchased', 'type': 'string'}}, 'required': ['product_name']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class BuypoductInputSchema(BaseModel):\n",
    "    product_name: str = Field(description=\"name of the product to be purchased\")\n",
    "\n",
    "@tool(\"buy_product-tool\", args_schema=BuypoductInputSchema, return_direct=True) \n",
    "### return_direct returns the output directly instead of sending it back to model\n",
    "def buy_product(product_name:str )->str:\n",
    "    \"\"\"   \n",
    "    the stock availale is updated with each purchase\n",
    "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "    \"\"\"\n",
    "    for product in estore_data['products']:\n",
    "        if product['name'] == product_name.lower():\n",
    "            if product['quantity_available'] > 0:\n",
    "                product['quantity_available'] -= 1\n",
    "                product['items_sold'] += 1\n",
    "                return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "            else:\n",
    "                return f\"Regret, {product_name} is not in stock.\"\n",
    "    return f\"Product {product_name} not found.\"\n",
    "print(\"name:\", buy_product.name)\n",
    "print(\"description:\", buy_product.description)\n",
    "print(\"args schema:\", buy_product.args_schema.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d5bc7d-7792-4ea6-adbf-666bd987ea52",
   "metadata": {},
   "source": [
    "#### StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64b00f26-3f57-4de9-9fa6-615fe31eaf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, \n",
    "                                          # name=\"Calculator\",\n",
    "                                          # description=\"multiply numbers\",\n",
    "                                          # args_schema=CalculatorInput, ## pydantic class\n",
    "                                          coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f36b9-af87-4f8c-abcf-2473dede0d48",
   "metadata": {},
   "source": [
    "#### Subclass BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea32b40-b58d-45ae-820f-39ec867c2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: buy_product\n",
      "description:  the stock availale is updated with each purchase.\n",
      "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
      "    \n",
      "args schema: {'product_name': {'title': 'Product Name', 'description': 'name of the product to be purchased', 'type': 'string'}}\n",
      "invoking sync ...: mechanical keyboard purchase confirmed. Remaining stock 48\n",
      "invoking async ...: mechanical keyboard purchase confirmed. Remaining stock 47\n"
     ]
    }
   ],
   "source": [
    "# https://api.python.langchain.com/en/latest/tools/langchain_core.tools.BaseTool.html\n",
    "from typing import Optional, Type\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_core.tools import BaseTool\n",
    "buy_product_description = \"\"\" the stock availale is updated with each purchase.\n",
    "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
    "    \"\"\"\n",
    "\n",
    "class BuyProductTool(BaseTool):\n",
    "    name = \"buy_product\"\n",
    "    description = buy_product_description\n",
    "    args_schema: Type[BaseModel] = BuypoductInputSchema  ## created previously using pydantic\n",
    "    return_direct: bool = True\n",
    "\n",
    "    def _run(self, product_name: str, \n",
    "             run_manager: Optional[CallbackManagerForToolRun]=None,\n",
    "            ) -> str:\n",
    "        for product in estore_data['products']:\n",
    "            if product['name'] == product_name.lower():\n",
    "                if product['quantity_available'] > 0:\n",
    "                    product['quantity_available'] -= 1\n",
    "                    product['items_sold'] += 1\n",
    "                    return f\"{product_name} purchase confirmed. Remaining stock {product['quantity_available']}\"\n",
    "                else:\n",
    "                    return f\"Regret, {product_name} is not in stock.\"\n",
    "        return f\"Product {product_name} not found.\"\n",
    "\n",
    "    async def _arun(self, product_name: str, \n",
    "             run_manager: Optional[AsyncCallbackManagerForToolRun]=None,\n",
    "            ) -> str:\n",
    "         # If the calculation is cheap, you can just delegate to the sync implementation\n",
    "         # as shown below.\n",
    "         # If the sync calculation is expensive, you should delete the entire _arun method.\n",
    "         # LangChain will automatically provide a better implementation that will\n",
    "         # kick off the task in a thread to make sure it doesn't block other async code.\n",
    "         return self._run(product_name, run_manager=run_manager.get_sync())\n",
    "\n",
    "buyproduct_tool = BuyProductTool()\n",
    "print(\"name:\", buyproduct_tool.name)\n",
    "print(\"description:\", buyproduct_tool.description)\n",
    "print(\"args schema:\", buyproduct_tool.args)   \n",
    "print('invoking sync ...:', buyproduct_tool.invoke('mechanical keyboard'))\n",
    "print('invoking async ...:', await  buyproduct_tool.ainvoke('mechanical keyboard'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c653b-2e07-426a-9982-221038518626",
   "metadata": {},
   "source": [
    "#### Creating tools from Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "125add68-7b2e-4745-96f4-0d40bed70e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/myDev/llmapps/venv/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_style': {'title': 'Answer Style', 'type': 'string'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.language_models import GenericFakeChatModel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"Hello. Please respond in the style of {answer_style}.\")]\n",
    ")\n",
    "\n",
    "# Placeholder LLM\n",
    "llm = GenericFakeChatModel(messages=iter([\"hello matey\"]))\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "as_tool = chain.as_tool(\n",
    "    name=\"Style responder\", description=\"Description of when to use tool.\"\n",
    ")\n",
    "as_tool.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de1921e-8b3a-4eac-8b86-f6374cad2b5c",
   "metadata": {},
   "source": [
    "#### tool for the calculate revenue with handle_tool_error exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31ddade-83bc-4e35-a4b5-e76bcccd8118",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Sometimes there are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself. For example if a tool returns custom objects like Documents, we may want to pass some view or metadata about this output to the model without passing the raw output to the model. At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.\n",
    "The Tool and ToolMessage interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).\n",
    "If we invoke our tool with a ToolCall (like the ones generated by tool-calling models), we'll get back a ToolMessage that contains both the content and artifact generated by the Tool.\n",
    "REQUIRES langchain-core >= 0.2.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32436db5-30c7-4b28-81bb-6f930afc1e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: calculate_revenue\n",
      "description:  returns revenue for the product or total revenue when no product name is mentione\n",
      "    \n",
      "args schema: {'product_name': {'title': 'Product Name', 'description': 'name of the product to be purchased', 'type': 'string'}}\n",
      "invoking sync with ToolCall format to get ToolMessage ...:\n",
      "\u001b[32;1m\u001b[1;3mcontent='Revenue for mechanical keyboard: $6239.22' name='calculate_revenue' tool_call_id='1' artifact={'wireless mouse': 3950.4799999999996, 'mechanical keyboard': 6239.219999999999, 'usb-c hub': 4268.780000000001}\u001b[0mtool_message ...: content='Revenue for mechanical keyboard: $6239.22' name='calculate_revenue' tool_call_id='1' artifact={'wireless mouse': 3950.4799999999996, 'mechanical keyboard': 6239.219999999999, 'usb-c hub': 4268.780000000001}\n",
      "\u001b[32;1m\u001b[1;3mRevenue for mechanical keyboard: $6239.22\u001b[0minvoking async ...: Revenue for mechanical keyboard: $6239.22\n",
      "\u001b[32;1m\u001b[1;3mRevenue for mechanical keyboard: $6239.22\u001b[0mhandle_tool_error ToolException sync ...: Revenue for mechanical keyboard: $6239.22\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "from typing import Union, Callable, Literal\n",
    "\n",
    "class CalcRevInputSchema(BaseModel):\n",
    "    product_name: str = Field(description=\"name of the product to be purchased\")\n",
    "\n",
    "calculate_revenue_description = \"\"\" returns revenue for the product or total revenue when no product name is mentione\n",
    "    \"\"\"\n",
    "\n",
    "class CalculateRevenueTool(BaseTool):\n",
    "    name = \"calculate_revenue\"\n",
    "    description = calculate_revenue_description\n",
    "    args_schema: Type[BaseModel] = CalcRevInputSchema\n",
    "    return_direct: bool = True ## the AgentExecutor will stop looping, output does not go to model\n",
    "    # handle_tool_error = True ## or a string message or a callable function. will not work. use typing \n",
    "    handle_tool_error: Optional[Union[bool, str, Callable[[ToolException], str]]] = True\n",
    "    response_format: Literal['content', 'content_and_artifact'] = 'content_and_artifact' ## or content\n",
    "    ## metadata: Optional[Dict[str, Any]] = None , ###Optional metadata associated with the tool. Defaults to None. This metadata will be associated with each call to this tool, and passed as arguments to the handlers defined in callbacks. You can use these to eg identify a specific instance of a tool with its use case.\n",
    "    verbose: bool = True\n",
    "\n",
    "    \n",
    "    def _run(self, product_name: str=None, \n",
    "             run_manager: Optional[CallbackManagerForToolRun]=None,\n",
    "            ) -> str:\n",
    "        total_revenue = 0.0\n",
    "        artifact_prodct_wise_rev = {}\n",
    "        for product in estore_data['products']:\n",
    "            artifact_prodct_wise_rev[product[\"name\"]] = product['items_sold'] * product['price']\n",
    "        for product in estore_data['products']:\n",
    "            if product_name and product['name'] == product_name.lower():\n",
    "                content = f\"Revenue for {product_name}: ${product['items_sold'] * product['price']:.2f}\"\n",
    "                return content, artifact_prodct_wise_rev\n",
    "            total_revenue += product['items_sold'] * product['price']\n",
    "        if product_name is None:\n",
    "            content = f\"Total revenue: ${total_revenue:.2f}\"\n",
    "            return content, artifact_prodct_wise_rev\n",
    "        # return f\"Product {product_name} not found.\" instead we will use ToolException        \n",
    "        raise ToolException(f\"Product {product_name} not found.\")\n",
    "\n",
    "    async def _arun(self, product_name: str=None, \n",
    "             run_manager: Optional[AsyncCallbackManagerForToolRun]=None,\n",
    "            ) -> str:         \n",
    "         return self._run(product_name, run_manager=run_manager.get_sync())\n",
    "\n",
    "calculate_revenue_tool = CalculateRevenueTool()\n",
    "print(\"name:\", calculate_revenue_tool.name)\n",
    "print(\"description:\", calculate_revenue_tool.description)\n",
    "print(\"args schema:\", calculate_revenue_tool.args)\n",
    "print('invoking sync with ToolCall format to get ToolMessage ...:' )\n",
    "tool_message = calculate_revenue_tool.invoke(\n",
    "    {\n",
    "        \"name\": \"calculate_revenue_tool\",\n",
    "        \"args\": {\"product_name\": \"mechanical keyboard\"},\n",
    "        \"id\": \"1\" , ## required field\n",
    "        \"type\": \"tool_call\", ## required field\n",
    "    }\n",
    ")     \n",
    "print('tool_message ...:', tool_message)\n",
    "print('invoking async ...:', await  calculate_revenue_tool.ainvoke('mechanical keyboard'))\n",
    "print('handle_tool_error ToolException sync ...:', calculate_revenue_tool.invoke('mechanical keyboard'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b02d9d-ecfe-42eb-9744-04404f8d76fd",
   "metadata": {},
   "source": [
    "### Use the tool inside prompt, instead of hard coded prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c6ded81b-74f4-46fa-b347-bc21301e8e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'product_name': {'title': 'Product Name',\n",
       "  'description': 'name of the product to be purchased',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_revenue_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c21fc600-80e3-4a83-9655-a7dbcb8774b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product_name']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_list = list(calculate_revenue_tool.args.keys())\n",
    "args_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2112d8-d6b0-4583-b8f2-d04ee3c29829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cb55376-cdc5-40ef-800f-80bca4e28ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy_product: product_name \n",
      " the stock availale is updated with each purchase.\n",
      "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
      "    \n",
      "\n",
      "calculate_revenue: product_name \n",
      " returns revenue for the product or total revenue when no product name is mentione\n",
      "    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "# tools = [CalculateRevenueTool(), BuyProductTool()]\n",
    "tools = [buyproduct_tool, calculate_revenue_tool]\n",
    "\n",
    "def generate_action_prompt(tools: List):\n",
    "    action_list_txt = \"\"\n",
    "    for tool in tools:\n",
    "        args_list = list(tool.args.keys())\n",
    "        args_as_text = \", \".join(args_list)\n",
    "        action_signature = f\"{tool.name}: {args_as_text} \\n\"\n",
    "        action_description = f\"{tool.description}\\n\\n\"\n",
    "        action_list_txt += action_signature + action_description\n",
    "    return action_list_txt\n",
    "action_list_txt = generate_action_prompt(tools)\n",
    "print(action_list_txt)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6df45625-9df9-43e3-a0b7-0bce4beb836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "react_instruction_str = \"\"\"You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\"\"\"\n",
    "\n",
    "example_session_str = \"\"\"Example session:\n",
    "\n",
    "Question: I would like to buy a wireless mouse, can you despatch it please ?\n",
    "Thought: I should buy the wireless mouse using the buy_product action\n",
    "Action: buy_product: wireless mouse\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: wireless mouse purchase confirmed. Remaining stock 40.\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: Thanks for your order. Your wireless mouse has been despatched to you. \n",
    "when the stock is not there you answer should be changed accordingly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22e18eda-1c8d-46b4-af9f-9d11cbeb6b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "buy_product: product_name \n",
      " the stock availale is updated with each purchase.\n",
      "    returns a confirmation message to the user or a regret message when item is not in stock. \n",
      "    \n",
      "\n",
      "calculate_revenue: product_name \n",
      " returns revenue for the product or total revenue when no product name is mentione\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: I would like to buy a wireless mouse, can you despatch it please ?\n",
      "Thought: I should buy the wireless mouse using the buy_product action\n",
      "Action: buy_product: wireless mouse\n",
      "PAUSE\n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: wireless mouse purchase confirmed. Remaining stock 40.\n",
      "\n",
      "You then output:\n",
      "\n",
      "Answer: Thanks for your order. Your wireless mouse has been despatched to you. \n",
      "when the stock is not there you answer should be changed accordingly\n"
     ]
    }
   ],
   "source": [
    "sys_template_string_agent = \"\"\"\n",
    "{react_instruction_str}\n",
    "\n",
    "{action_list_txt}\n",
    "\n",
    "{example_session_str}\n",
    "\"\"\"\n",
    "agent_react_prompt_with_var = sys_template_string_agent.format(\n",
    "    react_instruction_str = react_instruction_str,\n",
    "    action_list_txt=action_list_txt,\n",
    "    example_session_str=example_session_str).strip()\n",
    "print(agent_react_prompt_with_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7925d77d-3e41-4ad1-893c-599f8349801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to buy both a wireless mouse and a USB-C hub using the buy_product action. I will first attempt to buy the wireless mouse and then the USB-C hub. \n",
      "Action: buy_product: wireless mouse\n",
      "PAUSE\n",
      "[<re.Match object; span=(0, 35), match='Action: buy_product: wireless mouse'>]\n",
      "buy_product wireless mouse\n",
      "calling buy_product: with arguments: wireless mouse\n",
      "observation: wireless mouse purchase confirmed. Remaining stock 97\n",
      "Thought: The wireless mouse purchase was successful. Now I will proceed to buy the USB-C hub. \n",
      "Action: buy_product: usb-c hub\n",
      "PAUSE\n",
      "[<re.Match object; span=(0, 30), match='Action: buy_product: usb-c hub'>]\n",
      "buy_product usb-c hub\n",
      "calling buy_product: with arguments: usb-c hub\n",
      "observation: Regret, usb-c hub is not in stock.\n",
      "Answer: Thanks for your order. Your wireless mouse has been despatched to you. Unfortunately, the USB-C hub is currently out of stock.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"can you buy me one wireless mouse and one usb-c hub ? \"\"\"\n",
    "autoagent(question, prompt=agent_react_prompt_with_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8cba34e-d446-44a8-a053-a02ab0f99d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseChatModel.bind_tools of GenericFakeChatModel(messages=<list_iterator object at 0x7f63b4421790>)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.bind_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61929d73-ac44-4ccd-9c9e-d0f8e5652b5c",
   "metadata": {},
   "source": [
    "For the models that use tool calling, no special prompting is needed. ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd6a1f-61de-4600-a79b-1d1b8413a4a9",
   "metadata": {},
   "source": [
    "###  Understanding Langchain Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13bc099a-f489-43a4-ae43-03a25fb9b12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt template for chat models.\n",
      "\n",
      "    Use to create flexible templated prompts for chat models.\n",
      "\n",
      "    Examples:\n",
      "\n",
      "        .. versionchanged:: 0.2.24\n",
      "\n",
      "            You can pass any Message-like formats supported by\n",
      "            ``ChatPromptTemplate.from_messages()`` directly to ``ChatPromptTemplate()``\n",
      "            init.\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain_core.prompts import ChatPromptTemplate\n",
      "\n",
      "            template = ChatPromptTemplate([\n",
      "                (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
      "                (\"human\", \"Hello, how are you doing?\"),\n",
      "                (\"ai\", \"I'm doing well, thanks!\"),\n",
      "                (\"human\", \"{user_input}\"),\n",
      "            ])\n",
      "\n",
      "            prompt_value = template.invoke(\n",
      "                {\n",
      "                    \"name\": \"Bob\",\n",
      "                    \"user_input\": \"What is your name?\"\n",
      "                }\n",
      "            )\n",
      "            # Output:\n",
      "            # ChatPromptValue(\n",
      "            #    messages=[\n",
      "            #        SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
      "            #        HumanMessage(content='Hello, how are you doing?'),\n",
      "            #        AIMessage(content=\"I'm doing well, thanks!\"),\n",
      "            #        HumanMessage(content='What is your name?')\n",
      "            #    ]\n",
      "            #)\n",
      "\n",
      "    Messages Placeholder:\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            # In addition to Human/AI/Tool/Function messages,\n",
      "            # you can initialize the template with a MessagesPlaceholder\n",
      "            # either using the class directly or with the shorthand tuple syntax:\n",
      "\n",
      "            template = ChatPromptTemplate([\n",
      "                (\"system\", \"You are a helpful AI bot.\"),\n",
      "                # Means the template will receive an optional list of messages under\n",
      "                # the \"conversation\" key\n",
      "                (\"placeholder\", \"{conversation}\")\n",
      "                # Equivalently:\n",
      "                # MessagesPlaceholder(variable_name=\"conversation\", optional=True)\n",
      "            ])\n",
      "\n",
      "            prompt_value = template.invoke(\n",
      "                {\n",
      "                    \"conversation\": [\n",
      "                        (\"human\", \"Hi!\"),\n",
      "                        (\"ai\", \"How can I assist you today?\"),\n",
      "                        (\"human\", \"Can you make me an ice cream sundae?\"),\n",
      "                        (\"ai\", \"No.\")\n",
      "                    ]\n",
      "                }\n",
      "            )\n",
      "\n",
      "            # Output:\n",
      "            # ChatPromptValue(\n",
      "            #    messages=[\n",
      "            #        SystemMessage(content='You are a helpful AI bot.'),\n",
      "            #        HumanMessage(content='Hi!'),\n",
      "            #        AIMessage(content='How can I assist you today?'),\n",
      "            #        HumanMessage(content='Can you make me an ice cream sundae?'),\n",
      "            #        AIMessage(content='No.'),\n",
      "            #    ]\n",
      "            #)\n",
      "\n",
      "    Single-variable template:\n",
      "\n",
      "        If your prompt has only a single input variable (i.e., 1 instance of \"{variable_nams}\"),\n",
      "        and you invoke the template with a non-dict object, the prompt template will\n",
      "        inject the provided argument into that variable location.\n",
      "\n",
      "\n",
      "        .. code-block:: python\n",
      "\n",
      "            from langchain_core.prompts import ChatPromptTemplate\n",
      "\n",
      "            template = ChatPromptTemplate([\n",
      "                (\"system\", \"You are a helpful AI bot. Your name is Carl.\"),\n",
      "                (\"human\", \"{user_input}\"),\n",
      "            ])\n",
      "\n",
      "            prompt_value = template.invoke(\"Hello, there!\")\n",
      "            # Equivalent to\n",
      "            # prompt_value = template.invoke({\"user_input\": \"Hello, there!\"})\n",
      "\n",
      "            # Output:\n",
      "            #  ChatPromptValue(\n",
      "            #     messages=[\n",
      "            #         SystemMessage(content='You are a helpful AI bot. Your name is Carl.'),\n",
      "            #         HumanMessage(content='Hello, there!'),\n",
      "            #     ]\n",
      "            # )\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(ChatPromptTemplate.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "090f776b-41e0-43bb-9529-0ae0efd53c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain                 0.2.11\n",
      "langchain-community       0.2.10\n",
      "langchain-core            0.2.25\n",
      "langchain-experimental    0.0.63\n",
      "langchain-openai          0.1.17\n",
      "langchain-text-splitters  0.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.2 is available.\n",
      "You should consider upgrading via the '/mnt/d/myDev/llmapps/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "293b6444-c51a-401b-9303-4e82b46f8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4d71d04-8e31-4fda-9498-fd320da48f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=[] optional_variables=['conversation'] input_types={'conversation': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} partial_variables={'conversation': []} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful AI bot.')), MessagesPlaceholder(variable_name='conversation', optional=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful AI bot.'), HumanMessage(content='Hi!'), AIMessage(content='How can I assist you today?'), HumanMessage(content='Can you make me an ice cream sundae?'), AIMessage(content='No.')])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate([\n",
    "                (\"system\", \"You are a helpful AI bot.\"),\n",
    "                # Means the template will receive an optional list of messages under\n",
    "                # the \"conversation\" key\n",
    "                (\"placeholder\", \"{conversation}\")\n",
    "                # Equivalently:\n",
    "                # MessagesPlaceholder(variable_name=\"conversation\", optional=True)\n",
    "            ])\n",
    "print(template)\n",
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"conversation\": [\n",
    "            (\"human\", \"Hi!\"),\n",
    "            (\"ai\", \"How can I assist you today?\"),\n",
    "            (\"human\", \"Can you make me an ice cream sundae?\"),\n",
    "            (\"ai\", \"No.\")\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c8bbd72-d6f4-4de5-97d9-70ae5ae93515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['greetings', 'user_input'] optional_variables=['greetings'] partial_variables={'bot_name': 'Monalisa'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['bot_name'], template='You are a helpful AI bot. Your name is {bot_name}.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Hello, how are you doing?')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['greetings'], template=\"{greetings}, I'm doing well, thanks!\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))]\n",
      "\"Input to ChatPromptTemplate is missing variables {'greetings'}.  Expected: ['greetings', 'user_input'] Received: ['user_input']\"\n"
     ]
    }
   ],
   "source": [
    "template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {bot_name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"{greetings}, I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    ],\n",
    "    input_variables=['user_input'],\n",
    "    optional_variables=[\"greetings\"],\n",
    "    partial_variables={\"bot_name\": \"Monalisa\"}                            \n",
    "\n",
    ")\n",
    "print(template)\n",
    "final_input = {            \n",
    "            \"user_input\": \"What is your name?\"\n",
    "        }\n",
    "try:\n",
    "    prompt_value = template.invoke(final_input)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# # print(prompt_value)\n",
    "# template_partial = template.partial(bot_name=\"Monalisa\")\n",
    "# print(template_partial)\n",
    "# try:\n",
    "#     template_partial.invoke(final_input)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50fa923d-0a5f-4a5f-8f31-dae91ea4eabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='Tell me a joke about cats')])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e405f3f-ce2c-4155-848e-b963330d6358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant'), HumanMessage(content='hi!'), HumanMessage(content='How are you')])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    # (\"system\", \"You are a helpful assistant\"),\n",
    "    SystemMessage(content='You are a helpful assistant'),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\"), HumanMessage(content=\"How are you\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aea1eeae-9d28-4886-a3b1-876965a2dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdb3816f-6e1d-47a5-8cd4-825b9c27ebb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['action_list_txt', 'example_session_str', 'react_instruction_str'], template='\\n{react_instruction_str}\\n\\n{action_list_txt}\\n\\n{example_session_str}\\n'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_sys_prompt_agent = SystemMessagePromptTemplate.from_template(sys_template_string_agent)\n",
    "lc_sys_prompt_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d8135d8-3dad-4d55-a4eb-1d8c74e3f576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action_list_txt', 'example_session_str', 'react_instruction_str']\n",
      "\n",
      "{react_instruction_str}\n",
      "\n",
      "{action_list_txt}\n",
      "\n",
      "{example_session_str}\n",
      "\n",
      "content='\\nYou run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\nbuy_product: product_name \\n the stock availale is updated with each purchase.\\n    returns a confirmation message to the user or a regret message when item is not in stock. \\n    \\n\\ncalculate_revenue: product_name \\n returns revenue for the product or total revenue when no product name is mentione\\n    \\n\\n\\n\\nExample session:\\n\\nQuestion: I would like to buy a wireless mouse, can you despatch it please ?\\nThought: I should buy the wireless mouse using the buy_product action\\nAction: buy_product: wireless mouse\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: wireless mouse purchase confirmed. Remaining stock 40.\\n\\nYou then output:\\n\\nAnswer: Thanks for your order. Your wireless mouse has been despatched to you. \\nwhen the stock is not there you answer should be changed accordingly\\n'\n"
     ]
    }
   ],
   "source": [
    "print(lc_sys_prompt_agent.prompt.input_variables)\n",
    "print(lc_sys_prompt_agent.prompt.template)\n",
    "print(lc_sys_prompt_agent.format(\n",
    "    react_instruction_str = react_instruction_str,\n",
    "    action_list_txt=action_list_txt,\n",
    "    example_session_str=example_session_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e56fe1-be6b-4837-bc04-0b3daeaad410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f15208c-6990-4e75-a73e-5baba167523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system=\"\"):\n",
    "        self.system = system\n",
    "        self.messages = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            temperature=0,\n",
    "            messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8f7e7-e00f-4b55-9b9c-a1d3e0e96852",
   "metadata": {},
   "source": [
    "https://lilianweng.github.io/posts/2023-06-23-agent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b3e117-711c-4029-98dc-a72e850bb97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
